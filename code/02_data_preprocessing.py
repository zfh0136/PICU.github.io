
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
import warnings
warnings.filterwarnings('ignore')

def load_preprocessed_data():
    """åŠ è½½å·²ç»è¯»å–çš„æ•°æ®"""
    from pathlib import Path
    import sys
    
    project_root = Path(__file__).parent.parent
    processed_dir = project_root / "data" / "processed"
    file_path = processed_dir / "icu_data_loaded.csv"
    
    if not file_path.exists():
        print("è¯·å…ˆè¿è¡Œ01_data_loading.py")
        return None
    
    df = pd.read_csv(file_path)
    return df

def remove_useless_target(df):
    """
    å¤„ç†ç›®æ ‡å˜é‡é—®é¢˜
    is_early_death å…¨æ˜¯0ï¼Œåˆ é™¤æ­¤åˆ—
    """
    if 'is_early_death' in df.columns:
        print(f"åˆ é™¤æ— æ•ˆç›®æ ‡å˜é‡ 'is_early_death'ï¼ˆå…¨æ˜¯0ï¼‰")
        df = df.drop(columns=['is_early_death'])
    
    # æ£€æŸ¥ HOSPITAL_EXPIRE_FLAG æ˜¯å¦æœ‰æ•ˆ
    if 'HOSPITAL_EXPIRE_FLAG' in df.columns:
        positive_rate = df['HOSPITAL_EXPIRE_FLAG'].mean()
        print(f"ç›®æ ‡å˜é‡ 'HOSPITAL_EXPIRE_FLAG' é˜³æ€§ç‡: {positive_rate:.2%}")
        print(f"é˜³æ€§æ ·æœ¬æ•°: {df['HOSPITAL_EXPIRE_FLAG'].sum()}")
        print(f"é˜´æ€§æ ·æœ¬æ•°: {(df['HOSPITAL_EXPIRE_FLAG'] == 0).sum()}")
    
    return df

def handle_outliers(df):
    """
    å¤„ç†å¼‚å¸¸å€¼
    """
    print("\n å¤„ç†å¼‚å¸¸å€¼ï¼š")
    
    # 1. å¹´é¾„å¼‚å¸¸å€¼ï¼š-1ä¸ªæœˆ
    age_negative = (df['age_month'] < 0).sum()
    if age_negative > 0:
        print(f"  å‘ç° {age_negative} æ¡å¹´é¾„ä¸ºè´Ÿå€¼çš„è®°å½•")
                # è®¾ä¸º0ï¼ˆæ–°ç”Ÿå„¿ï¼‰
        df.loc[df['age_month'] < 0, 'age_month'] = 0
        print("  å·²å°†è´Ÿå¹´é¾„è®¾ä¸º0ï¼ˆæ–°ç”Ÿå„¿ï¼‰")
    
    # 2. ä½“é‡å¼‚å¸¸å€¼ï¼š0kg
    weight_zero = (df['weight_kg'] == 0).sum()
    if weight_zero > 0:
        print(f"  å‘ç° {weight_zero} æ¡ä½“é‡ä¸º0çš„è®°å½•ï¼ˆå ä½“é‡è®°å½•çš„{weight_zero/df['weight_kg'].notna().sum():.1%}ï¼‰")
                # å…ˆä¸å¤„ç†ï¼Œåç»­ç”¨å¹´é¾„ä¼°ç®—
    
    # 3. æ£€æŸ¥å¹´é¾„èŒƒå›´
    print(f"  å¹´é¾„èŒƒå›´: {df['age_month'].min():.0f}-{df['age_month'].max():.0f} ä¸ªæœˆ")
    print(f"  ä½“é‡èŒƒå›´: {df['weight_kg'].min():.1f}-{df['weight_kg'].max():.1f} kg")
    
    return df

def extract_date_features(df):
    """
    ä»ADMITTIMEæå–æ—¶é—´ç‰¹å¾
    """
    if 'ADMITTIME' in df.columns:
        print("\n æå–æ—¶é—´ç‰¹å¾ï¼š")
        
        # å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºdatetime
        df['ADMITTIME'] = pd.to_datetime(df['ADMITTIME'], errors='coerce')
        
        # æå–æ—¶é—´ç‰¹å¾
        df['admit_year'] = df['ADMITTIME'].dt.year
        df['admit_month'] = df['ADMITTIME'].dt.month
        df['admit_day'] = df['ADMITTIME'].dt.day
        df['admit_hour'] = df['ADMITTIME'].dt.hour
        df['admit_dayofweek'] = df['ADMITTIME'].dt.dayofweek  # å‘¨ä¸€=0, å‘¨æ—¥=6
        df['admit_season'] = df['ADMITTIME'].dt.month % 12 // 3 + 1  # å­£èŠ‚
        
        print(f"  æå–äº† {df['admit_year'].nunique()} ä¸ªä¸åŒå¹´ä»½çš„æ•°æ®")
        print(f"  å…¥é™¢æ—¶é—´èŒƒå›´: {df['ADMITTIME'].min()} åˆ° {df['ADMITTIME'].max()}")
    
    return df

def feature_selection_via_missingness(df, missing_threshold=0.8):
    """
    åŸºäºç¼ºå¤±ç‡è¿›è¡Œç‰¹å¾é€‰æ‹©
    åˆ é™¤ç¼ºå¤±ç‡è¿‡é«˜çš„ç‰¹å¾
    """
    print(f"\n åŸºäºç¼ºå¤±ç‡çš„ç‰¹å¾é€‰æ‹©ï¼ˆé˜ˆå€¼={missing_threshold:.0%}ï¼‰ï¼š")
    
    # è®¡ç®—æ¯ä¸ªç‰¹å¾çš„ç¼ºå¤±ç‡
    missing_rates = df.isnull().sum() / len(df)
    
    # é€‰æ‹©ç¼ºå¤±ç‡ä½äºé˜ˆå€¼çš„ç‰¹å¾
    selected_features = missing_rates[missing_rates < missing_threshold].index.tolist()
    
    print(f"  åŸå§‹ç‰¹å¾æ•°: {len(df.columns)}")
    print(f"  åˆ é™¤ç¼ºå¤±ç‡ > {missing_threshold:.0%} çš„ç‰¹å¾å: {len(selected_features)}")
    print(f"  åˆ é™¤äº† {len(df.columns) - len(selected_features)} ä¸ªç‰¹å¾")
    
    # ä¿å­˜è¢«åˆ é™¤çš„ç‰¹å¾
    removed_features = missing_rates[missing_rates >= missing_threshold].index.tolist()
    print(f"  å‰10ä¸ªè¢«åˆ é™¤çš„é«˜ç¼ºå¤±ç‰¹å¾: {removed_features[:10]}")
    
    return df[selected_features]

def handle_missing_values(df, strategy='median'):
    """
    å¤„ç†ç¼ºå¤±å€¼
    """
    print(f"\n å¤„ç†ç¼ºå¤±å€¼ï¼ˆç­–ç•¥: {strategy}ï¼‰ï¼š")
    
    # åˆ†ç¦»æ•°å€¼ç‰¹å¾å’Œåˆ†ç±»ç‰¹å¾
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    
    # ç§»é™¤ç›®æ ‡å˜é‡ï¼ˆå¦‚æœæœ‰ï¼‰
    target_cols = ['HOSPITAL_EXPIRE_FLAG', 'SUBJECT_ID', 'HADM_ID']
    numeric_cols = [col for col in numeric_cols if col not in target_cols]
    
    # è®¡ç®—å¡«å……å‰çš„ç¼ºå¤±æƒ…å†µ
    missing_before = df[numeric_cols].isnull().sum().sum()
    total_cells = df[numeric_cols].size
    print(f"  æ•°å€¼ç‰¹å¾ç¼ºå¤±å€¼: {missing_before} ({missing_before/total_cells:.1%})")
    
    # å¡«å……æ•°å€¼ç‰¹å¾
    if strategy == 'median':
        df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())
    elif strategy == 'mean':
        df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())
    elif strategy == 'zero':
        df[numeric_cols] = df[numeric_cols].fillna(0)
    
    # è®¡ç®—å¡«å……åçš„ç¼ºå¤±æƒ…å†µ
    missing_after = df[numeric_cols].isnull().sum().sum()
    print(f"  å¡«å……åæ•°å€¼ç‰¹å¾ç¼ºå¤±å€¼: {missing_after}")
    
    # å¤„ç†åˆ†ç±»ç‰¹å¾ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
    categorical_cols = [col for col in categorical_cols if col not in target_cols]
    
    if categorical_cols:
        # ç”¨ä¼—æ•°å¡«å……
        for col in categorical_cols:
            mode_value = df[col].mode()[0] if not df[col].mode().empty else 'Unknown'
            df[col] = df[col].fillna(mode_value)
    
    return df

def handle_class_imbalance(X, y):
    """
    å¤„ç†ç±»åˆ«ä¸å¹³è¡¡
    ä½¿ç”¨SMOTEè¿‡é‡‡æ ·
    """
    print("\n å¤„ç†ç±»åˆ«ä¸å¹³è¡¡ï¼š")
    print(f"  é‡‡æ ·å‰ - ç±»åˆ«0: {(y == 0).sum()}, ç±»åˆ«1: {(y == 1).sum()}")
    print(f"  ä¸å¹³è¡¡æ¯”ä¾‹: {(y == 0).sum() / len(y):.1%} : {(y == 1).sum() / len(y):.1%}")
    
    # ä½¿ç”¨SMOTEè¿‡é‡‡æ ·
    try:
        smote = SMOTE(random_state=42, sampling_strategy=0.3)  # å°†å°‘æ•°ç±»å¢åŠ åˆ°30%
        X_resampled, y_resampled = smote.fit_resample(X, y)
        
        print(f"  é‡‡æ ·å - ç±»åˆ«0: {(y_resampled == 0).sum()}, ç±»åˆ«1: {(y_resampled == 1).sum()}")
        print(f"  æ–°æ¯”ä¾‹: {(y_resampled == 0).sum() / len(y_resampled):.1%} : {(y_resampled == 1).sum() / len(y_resampled):.1%}")
        
        return X_resampled, y_resampled
    except Exception as e:
        print(f"  SMOTEå¤±è´¥: {e}")
        print("  è¿”å›åŸå§‹æ•°æ®")
        return X, y

def prepare_features_and_target(df):
    """
    å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡
    """
    print("\n å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡ï¼š")
    
    # ç¡®å®šç›®æ ‡å˜é‡
    target = 'HOSPITAL_EXPIRE_FLAG'
    
    # è¦æ’é™¤çš„ç‰¹å¾ï¼ˆIDã€æ—¶é—´æˆ³ç­‰ï¼‰
    exclude_cols = ['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', target]
    
    # ç‰¹å¾åˆ—
    feature_cols = [col for col in df.columns if col not in exclude_cols]
    
    print(f"  ç‰¹å¾æ•°é‡: {len(feature_cols)}")
    print(f"  ç›®æ ‡å˜é‡: {target}")
    
    X = df[feature_cols]
    y = df[target]
    
    return X, y, feature_cols

def split_data_by_patient(df, test_size=0.2):
    """
    æŒ‰æ‚£è€…åˆ†å‰²æ•°æ®ï¼Œç¡®ä¿åŒä¸€ä¸ªæ‚£è€…ä¸å‡ºç°åœ¨è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸­
    """
    print("\n æŒ‰æ‚£è€…åˆ†å‰²æ•°æ®ï¼š")
    
    # è·å–æ‚£è€…IDåˆ—è¡¨
    patient_ids = df['SUBJECT_ID'].unique()
    print(f"  å”¯ä¸€æ‚£è€…æ•°: {len(patient_ids)}")
    print(f"  æ€»è®°å½•æ•°: {len(df)}")
    
    # æŒ‰æ‚£è€…åˆ†å‰²
    train_patients, test_patients = train_test_split(
        patient_ids, test_size=test_size, random_state=42, stratify=None
    )
    
    # åˆ›å»ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†
    train_df = df[df['SUBJECT_ID'].isin(train_patients)]
    test_df = df[df['SUBJECT_ID'].isin(test_patients)]
    
    print(f"  è®­ç»ƒé›†æ‚£è€…æ•°: {len(train_patients)} ({len(train_df)} æ¡è®°å½•)")
    print(f"  æµ‹è¯•é›†æ‚£è€…æ•°: {len(test_patients)} ({len(test_df)} æ¡è®°å½•)")
    
    return train_df, test_df

def save_processed_data(train_df, test_df, feature_cols):
    """
    ä¿å­˜å¤„ç†åçš„æ•°æ®
    """
    from pathlib import Path
    
    project_root = Path(__file__).parent.parent
    processed_dir = project_root / "data" / "processed"
    processed_dir.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜æ•°æ®
    train_df.to_csv(processed_dir / "train_data.csv", index=False)
    test_df.to_csv(processed_dir / "test_data.csv", index=False)
    
    # ä¿å­˜ç‰¹å¾åˆ—è¡¨
    feature_df = pd.DataFrame({'feature': feature_cols})
    feature_df.to_csv(processed_dir / "feature_list.csv", index=False)
    
    print(f"\nğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {processed_dir}")
    print(f"  è®­ç»ƒé›†: train_data.csv ({len(train_df)} è¡Œ)")
    print(f"  æµ‹è¯•é›†: test_data.csv ({len(test_df)} è¡Œ)")
    print(f"  ç‰¹å¾åˆ—è¡¨: feature_list.csv ({len(feature_cols)} ä¸ªç‰¹å¾)")

def main_preprocessing_pipeline():
    """
    ä¸»é¢„å¤„ç†æµç¨‹
    """
    print("=" * 60)
    print("ICUæ•°æ®é¢„å¤„ç†æ¨¡å—")
    print("=" * 60)
    
    # 1. åŠ è½½æ•°æ®
    print("\n æ­¥éª¤1: åŠ è½½æ•°æ®")
    df = load_preprocessed_data()
    if df is None:
        return
    
    print(f"  åŸå§‹æ•°æ®å½¢çŠ¶: {df.shape}")
    
    # 2. å¤„ç†ç›®æ ‡å˜é‡
    print("\n æ­¥éª¤2: å¤„ç†ç›®æ ‡å˜é‡")
    df = remove_useless_target(df)
    
    # 3. å¤„ç†å¼‚å¸¸å€¼
    df = handle_outliers(df)
    
    # 4. æå–æ—¶é—´ç‰¹å¾
    df = extract_date_features(df)
    
    # 5. åŸºäºç¼ºå¤±ç‡çš„ç‰¹å¾é€‰æ‹©
    print("\n æ­¥éª¤3: ç‰¹å¾é€‰æ‹©")
    df = feature_selection_via_missingness(df, missing_threshold=0.5)  # 50%é˜ˆå€¼
    
    # 6. å¤„ç†ç¼ºå¤±å€¼
    print("\n æ­¥éª¤4: å¤„ç†ç¼ºå¤±å€¼")
    df = handle_missing_values(df, strategy='median')
    
    # 7. æŒ‰æ‚£è€…åˆ†å‰²æ•°æ®
    print("\n æ­¥éª¤5: æ•°æ®åˆ†å‰²")
    train_df, test_df = split_data_by_patient(df, test_size=0.2)
    
    # 8. å‡†å¤‡è®­ç»ƒé›†çš„ç‰¹å¾å’Œç›®æ ‡
    print("\n æ­¥éª¤6: å‡†å¤‡è®­ç»ƒæ•°æ®")
    X_train, y_train, feature_cols = prepare_features_and_target(train_df)
    
    # 9. å¤„ç†ç±»åˆ«ä¸å¹³è¡¡ï¼ˆåªåœ¨è®­ç»ƒé›†ä¸Šï¼‰
    print("\n æ­¥éª¤7: å¤„ç†ç±»åˆ«ä¸å¹³è¡¡ï¼ˆä»…è®­ç»ƒé›†ï¼‰")
    X_train_resampled, y_train_resampled = handle_class_imbalance(X_train, y_train)
    
    # 10. å‡†å¤‡æµ‹è¯•é›†çš„ç‰¹å¾å’Œç›®æ ‡
    X_test, y_test, _ = prepare_features_and_target(test_df)
    
    # 11. ä¿å­˜å¤„ç†åçš„æ•°æ®
    print("\n æ­¥éª¤8: ä¿å­˜æ•°æ®")
    # åˆ›å»ºåŒ…å«æ‰€æœ‰ç‰¹å¾çš„è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    train_df_processed = pd.DataFrame(X_train_resampled, columns=feature_cols)
    train_df_processed['HOSPITAL_EXPIRE_FLAG'] = y_train_resampled
    
    test_df_processed = pd.DataFrame(X_test, columns=feature_cols)
    test_df_processed['HOSPITAL_EXPIRE_FLAG'] = y_test
    
    # æ·»åŠ IDä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
    train_df_processed['SUBJECT_ID'] = np.random.choice(train_df['SUBJECT_ID'].unique(), 
                                                       size=len(train_df_processed))
    test_df_processed['SUBJECT_ID'] = test_df['SUBJECT_ID'].values
    
    save_processed_data(train_df_processed, test_df_processed, feature_cols)
    
    # 12. æ‰“å°æœ€ç»ˆæŠ¥å‘Š
    print("\n" + "=" * 60)
    print(" æ•°æ®é¢„å¤„ç†å®Œæˆï¼")
    print("=" * 60)
    print("\n æœ€ç»ˆæ•°æ®æŠ¥å‘Šï¼š")
    print(f"  è®­ç»ƒé›†å½¢çŠ¶: {train_df_processed.shape}")
    print(f"  æµ‹è¯•é›†å½¢çŠ¶: {test_df_processed.shape}")
    print(f"  ç‰¹å¾æ•°é‡: {len(feature_cols)}")
    print(f"  ç›®æ ‡å˜é‡åˆ†å¸ƒï¼ˆè®­ç»ƒé›†ï¼‰:")
    print(f"    ç±»åˆ«0: {(train_df_processed['HOSPITAL_EXPIRE_FLAG'] == 0).sum()}")
    print(f"    ç±»åˆ«1: {(train_df_processed['HOSPITAL_EXPIRE_FLAG'] == 1).sum()}")
    print(f"    é˜³æ€§ç‡: {train_df_processed['HOSPITAL_EXPIRE_FLAG'].mean():.2%}")
    
    return train_df_processed, test_df_processed, feature_cols

# ä¸»ç¨‹åºå…¥å£
if __name__ == "__main__":
    train_df, test_df, features = main_preprocessing_pipeline()